{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-07T12:00:40.890270Z","iopub.execute_input":"2024-06-07T12:00:40.890681Z","iopub.status.idle":"2024-06-07T12:00:42.203668Z","shell.execute_reply.started":"2024-06-07T12:00:40.890650Z","shell.execute_reply":"2024-06-07T12:00:42.201921Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/leash-BELKA/sample_submission.csv\n/kaggle/input/leash-BELKA/train.parquet\n/kaggle/input/leash-BELKA/test.parquet\n/kaggle/input/leash-BELKA/train.csv\n/kaggle/input/leash-BELKA/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!conda install -y -c intel mkl mkl-devel mkl-static mkl-include\n!apt-get install -y gfortran\n%env MKLROOT=/opt/conda/lib\n!pip3 install git+https://github.com/qmlcode/qml@develop --user -U\n!pip install duckdb\n!pip install molSimplify","metadata":{"execution":{"iopub.status.busy":"2024-06-07T12:03:28.804198Z","iopub.execute_input":"2024-06-07T12:03:28.804634Z","iopub.status.idle":"2024-06-07T12:08:18.930038Z","shell.execute_reply.started":"2024-06-07T12:03:28.804596Z","shell.execute_reply":"2024-06-07T12:08:18.928354Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Channels:\n - intel\n - rapidsai\n - nvidia\n - conda-forge\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - mkl\n    - mkl-devel\n    - mkl-include\n    - mkl-static\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    intel-openmp-2024.1.2      |        intel_995        20.3 MB  intel\n    mkl-2024.1.0               |        intel_691       156.3 MB  intel\n    mkl-devel-2024.1.0         |        intel_691          28 KB  intel\n    mkl-include-2024.1.0       |        intel_691         781 KB  intel\n    mkl-static-2024.1.0        |        intel_691       147.7 MB  intel\n    ------------------------------------------------------------\n                                           Total:       325.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n  intel-openmp       intel/linux-64::intel-openmp-2024.1.2-intel_995 \n  mkl-devel          intel/linux-64::mkl-devel-2024.1.0-intel_691 \n  mkl-include        intel/linux-64::mkl-include-2024.1.0-intel_691 \n  mkl-static         intel/linux-64::mkl-static-2024.1.0-intel_691 \n\nThe following packages will be SUPERSEDED by a higher-priority channel:\n\n  mkl                conda-forge::mkl-2024.1.0-ha957f24_693 --> intel::mkl-2024.1.0-intel_691 \n\n\n\nDownloading and Extracting Packages:\nmkl-2024.1.0         | 156.3 MB  |                                       |   0% \nmkl-static-2024.1.0  | 147.7 MB  |                                       |   0% \u001b[A\n\nintel-openmp-2024.1. | 20.3 MB   |                                       |   0% \u001b[A\u001b[A\n\n\nmkl-include-2024.1.0 | 781 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n\n\n\nmkl-devel-2024.1.0   | 28 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\nmkl-2024.1.0         | 156.3 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\nmkl-devel-2024.1.0   | 28 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\nmkl-2024.1.0         | 156.3 MB  |                                       |   0% \u001b[A\nmkl-2024.1.0         | 156.3 MB  | 1                                     |   0% \u001b[A\n                                                                                \u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n\n[Errno 2] No such file or directory: '/opt/conda/pkgs/mkl-include-2024.1.0-intel_691.tar.bz2.partial' -> '/opt/conda/pkgs/mkl-include-2024.1.0-intel_691.tar.bz2'\n[Errno 2] No such file or directory: '/opt/conda/pkgs/mkl-include-2024.1.0-intel_691.tar.bz2.partial' -> '/opt/conda/pkgs/mkl-include-2024.1.0-intel_691.tar.bz2'\n\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  gfortran-9 libgfortran-9-dev\nSuggested packages:\n  gfortran-multilib gfortran-doc gfortran-9-multilib gfortran-9-doc\n  libcoarrays-dev\nThe following NEW packages will be installed:\n  gfortran gfortran-9 libgfortran-9-dev\n0 upgraded, 3 newly installed, 0 to remove and 64 not upgraded.\nNeed to get 8622 kB of archives.\nAfter this operation, 33.1 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgfortran-9-dev amd64 9.4.0-1ubuntu1~20.04.2 [685 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gfortran-9 amd64 9.4.0-1ubuntu1~20.04.2 [7936 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal/main amd64 gfortran amd64 4:9.3.0-1ubuntu2 [1372 B]\nFetched 8622 kB in 22s (391 kB/s)                                              \nSelecting previously unselected package libgfortran-9-dev:amd64.\n(Reading database ... 110195 files and directories currently installed.)\nPreparing to unpack .../libgfortran-9-dev_9.4.0-1ubuntu1~20.04.2_amd64.deb ...\nUnpacking libgfortran-9-dev:amd64 (9.4.0-1ubuntu1~20.04.2) ...\nSelecting previously unselected package gfortran-9.\nPreparing to unpack .../gfortran-9_9.4.0-1ubuntu1~20.04.2_amd64.deb ...\nUnpacking gfortran-9 (9.4.0-1ubuntu1~20.04.2) ...\nSelecting previously unselected package gfortran.\nPreparing to unpack .../gfortran_4%3a9.3.0-1ubuntu2_amd64.deb ...\nUnpacking gfortran (4:9.3.0-1ubuntu2) ...\nSetting up libgfortran-9-dev:amd64 (9.4.0-1ubuntu1~20.04.2) ...\nSetting up gfortran-9 (9.4.0-1ubuntu1~20.04.2) ...\nSetting up gfortran (4:9.3.0-1ubuntu2) ...\nupdate-alternatives: using /usr/bin/gfortran to provide /usr/bin/f95 (f95) in auto mode\nupdate-alternatives: warning: skip creation of /usr/share/man/man1/f95.1.gz because associated file /usr/share/man/man1/gfortran.1.gz (of link group f95) doesn't exist\nupdate-alternatives: using /usr/bin/gfortran to provide /usr/bin/f77 (f77) in auto mode\nupdate-alternatives: warning: skip creation of /usr/share/man/man1/f77.1.gz because associated file /usr/share/man/man1/gfortran.1.gz (of link group f77) doesn't exist\nProcessing triggers for man-db (2.9.1-1) ...\nenv: MKLROOT=/opt/conda/lib\nCollecting git+https://github.com/qmlcode/qml@develop\n  Cloning https://github.com/qmlcode/qml (to revision develop) to /tmp/pip-req-build-v6yh0xjc\n  Running command git clone --filter=blob:none --quiet https://github.com/qmlcode/qml /tmp/pip-req-build-v6yh0xjc\n  Running command git checkout -b develop --track origin/develop\n  Switched to a new branch 'develop'\n  Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n  Resolved https://github.com/qmlcode/qml to commit a7921c9176b9498dcce096efad0883271706d633\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.10/site-packages (from qml==0.4.0.12) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from qml==0.4.0.12) (1.11.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from qml==0.4.0.12) (1.2.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from qml==0.4.0.12) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->qml==0.4.0.12) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->qml==0.4.0.12) (3.2.0)\nBuilding wheels for collected packages: qml\n  Building wheel for qml (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for qml: filename=qml-0.4.0.12-cp310-cp310-linux_x86_64.whl size=1661029 sha256=d687cad4474b71955021304f563a95cece05e5565df7df8b3a9cdb018c61da5f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-xs3trfok/wheels/ca/88/ae/e16db6274c00b722084d74335eae75359866c5f641681abca3\nSuccessfully built qml\nInstalling collected packages: qml\nSuccessfully installed qml-0.4.0.12\nRequirement already satisfied: duckdb in /opt/conda/lib/python3.10/site-packages (1.0.0)\nCollecting molSimplify\n  Using cached molSimplify-1.7.4-py3-none-any.whl.metadata (48 kB)\nCollecting openbabel-wheel (from molSimplify)\n  Using cached openbabel_wheel-3.1.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from molSimplify) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from molSimplify) (1.11.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from molSimplify) (2.2.2)\nRequirement already satisfied: networkx>=2.7 in /opt/conda/lib/python3.10/site-packages (from molSimplify) (3.2.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from molSimplify) (1.2.2)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from molSimplify) (3.3.3)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (from molSimplify) (2.15.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from molSimplify) (6.0.1)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from molSimplify) (6.1.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras->molSimplify) (1.4.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras->molSimplify) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras->molSimplify) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras->molSimplify) (3.10.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras->molSimplify) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras->molSimplify) (0.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->molSimplify) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->molSimplify) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->molSimplify) (2023.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->molSimplify) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->molSimplify) (3.2.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (16.0.6)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->molSimplify) (2.15.0)\nCollecting keras (from molSimplify)\n  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->molSimplify) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->molSimplify) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->molSimplify) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->molSimplify) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->molSimplify) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->molSimplify) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->molSimplify) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow->molSimplify) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->molSimplify) (3.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->molSimplify) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->molSimplify) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras->molSimplify) (0.1.2)\nDownloading molSimplify-1.7.4-py3-none-any.whl (15.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openbabel_wheel-3.1.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: openbabel-wheel, keras, molSimplify\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0 molSimplify-1.7.4 openbabel-wheel-3.1.1.19\n","output_type":"stream"}]},{"cell_type":"code","source":"# import libraries\nimport duckdb\nimport pandas as pd\nfrom qml.fchl import get_local_kernels, get_local_symmetric_kernels\nfrom qml import Compound\nfrom sklearn.base import BaseEstimator\nfrom sklearn.kernel_ridge import KernelRidge\nfrom io import StringIO\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nfrom molSimplify.Classes.mol3D import mol3D","metadata":{"execution":{"iopub.status.busy":"2024-06-07T12:12:41.365761Z","iopub.execute_input":"2024-06-07T12:12:41.366240Z","iopub.status.idle":"2024-06-07T12:12:41.374828Z","shell.execute_reply.started":"2024-06-07T12:12:41.366202Z","shell.execute_reply":"2024-06-07T12:12:41.373314Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# extract the 1145 unique building blocks\ntrain_path = '/kaggle/input/leash-BELKA/train.parquet'\ntest_path = '/kaggle/input/leash-BELKA/test.parquet'\n\ncon = duckdb.connect()\n\nmols = con.query(f\"\"\"(SELECT DISTINCT(building_blocks) as building_blocks FROM\n((SELECT DISTINCT(buildingblock1_smiles) as building_blocks\n                        FROM parquet_scan('{train_path}')\n                        )\n                        UNION ALL\n                        (SELECT DISTINCT(buildingblock2_smiles) as building_blocks\n                        FROM parquet_scan('{train_path}'))\n                        UNION ALL\n                        (SELECT DISTINCT(buildingblock3_smiles) as building_blocks\n                        FROM parquet_scan('{train_path}'))))\"\"\").df()\n\ncon.close()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T12:17:55.379130Z","iopub.execute_input":"2024-06-07T12:17:55.379699Z","iopub.status.idle":"2024-06-07T12:18:15.097624Z","shell.execute_reply.started":"2024-06-07T12:17:55.379658Z","shell.execute_reply":"2024-06-07T12:18:15.096027Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2232114e2b6f41fc9d71f9b015334be2"}},"metadata":{}}]},{"cell_type":"code","source":"mols.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T12:18:18.058317Z","iopub.execute_input":"2024-06-07T12:18:18.058739Z","iopub.status.idle":"2024-06-07T12:18:18.071367Z","shell.execute_reply.started":"2024-06-07T12:18:18.058709Z","shell.execute_reply":"2024-06-07T12:18:18.069917Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                     building_blocks\n0     C#CC[C@@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\n1    C=CCC[C@@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O\n2  CC(C)(C)OC(=O)CCC(NC(=O)OCC1c2ccccc2-c2ccccc21...\n3  CC(C)(C)OC(=O)N1CCN(C(=O)OCC2c3ccccc3-c3ccccc3...\n4          CCCCC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>building_blocks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C#CC[C@@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C=CCC[C@@H](NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CC(C)(C)OC(=O)CCC(NC(=O)OCC1c2ccccc2-c2ccccc21...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CC(C)(C)OC(=O)N1CCN(C(=O)OCC2c3ccccc3-c3ccccc3...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CCCCC(NC(=O)OCC1c2ccccc2-c2ccccc21)C(=O)O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"mols.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-07T12:18:18.895925Z","iopub.execute_input":"2024-06-07T12:18:18.896387Z","iopub.status.idle":"2024-06-07T12:18:18.904084Z","shell.execute_reply.started":"2024-06-07T12:18:18.896342Z","shell.execute_reply":"2024-06-07T12:18:18.902674Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(1145, 1)"},"metadata":{}}]},{"cell_type":"code","source":"# generate the FCHL representations for those building blocks\ndef make_xyz(mol_smiles):\n    mol_3d = mol3D()\n    mol_3d.read_smiles(mol_smiles)\n    return mol_3d.writexyz('', writestring=True)\n\ndef extract_num_atoms(molecule):\n    # Split the molecule string by new line and get the first line\n    first_line = molecule.split('\\n')[0]\n    # Convert the first line to an integer (number of atoms)\n    return int(first_line)\n\ndef make_representation(x, max_atoms):\n    # Step 1: Compute the representation\n    c = Compound(StringIO(x))\n    c.generate_fchl_representation(max_size=max_atoms)\n    \n    # Step 2: Return it\n    return c.representation\n\nclass FCHLKernel(BaseEstimator):\n    \"\"\"Class for computing the kernel matrix using the qml utility functions\n    \n    The input `X` to all of the function is a list of FCHL representation vectors\n    \n    Follows the \"BaseEstimator\" API so that we can \n    \"\"\"\n    \n    def __init__(self):\n        super(FCHLKernel, self).__init__()\n        self.train_points = None\n    \n    def fit(self, X, y=None):\n        # Store the training set\n        self.train_points = np.array(X)\n        return self\n        \n    def fit_transform(self, X, y=None):\n        self.fit(X)\n        # Uses the get_localget_local_symmetric_kernels to halve the\n        #  computational cost (as the matrix is symmetric)\n        return np.squeeze(get_local_symmetric_kernels(self.train_points))\n    \n    def transform(self, X, y=None):\n        return get_local_kernels(np.array(X), self.train_points)[0]\n\n# mols['xyz'] = mols['building_blocks'].apply(make_xyz)\n# num_atoms = mols['xyz'].apply(extract_num_atoms)\n# max_atoms = num_atoms.max()\n# mols['fchl_rep'] = mols['xyz'].apply(lambda x: make_representation(x, max_atoms))\nfchl_kernel = FCHLKernel()\nbuilding_block_kernel = fchl_kernel.fit_transform(mols['fchl_rep'].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:32:12.499627Z","iopub.execute_input":"2024-06-07T14:32:12.500171Z","iopub.status.idle":"2024-06-07T16:14:25.957247Z","shell.execute_reply.started":"2024-06-07T14:32:12.500122Z","shell.execute_reply":"2024-06-07T16:14:25.953810Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"type(building_block_kernel)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T16:25:25.551237Z","iopub.execute_input":"2024-06-07T16:25:25.551726Z","iopub.status.idle":"2024-06-07T16:25:25.561108Z","shell.execute_reply.started":"2024-06-07T16:25:25.551682Z","shell.execute_reply":"2024-06-07T16:25:25.559417Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"np.save('building_block_kernel.npy', building_block_kernel)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T16:26:31.456024Z","iopub.execute_input":"2024-06-07T16:26:31.456505Z","iopub.status.idle":"2024-06-07T16:26:31.477360Z","shell.execute_reply.started":"2024-06-07T16:26:31.456472Z","shell.execute_reply":"2024-06-07T16:26:31.475954Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"load_kernel = np.load('building_block_kernel.npy')","metadata":{"execution":{"iopub.status.busy":"2024-06-07T16:27:18.849647Z","iopub.execute_input":"2024-06-07T16:27:18.850076Z","iopub.status.idle":"2024-06-07T16:27:18.867163Z","shell.execute_reply.started":"2024-06-07T16:27:18.850046Z","shell.execute_reply":"2024-06-07T16:27:18.865666Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for i in (load_kernel == building_block_kernel)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T16:27:40.142048Z","iopub.execute_input":"2024-06-07T16:27:40.142500Z","iopub.status.idle":"2024-06-07T16:27:40.153222Z","shell.execute_reply.started":"2024-06-07T16:27:40.142464Z","shell.execute_reply":"2024-06-07T16:27:40.151836Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(1145, 1145)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Going from building block to molecular-level FCHL reps\n### see pseudo code below\n\n```python\ncollect N_train required molecules in training_set variable\nbuilding_block_kernel = 1145 x 1145 dimensional kernel matrix obtained from above\nfeature_matrix = [] which will contain the featurization of all the above N_train molecules\nfor molecule in training_set:\n    b1_fchl_transform = do a fchl_kernel.transform on the fchl_rep of building block 1 for that molecule using the above building_block_kernel to get a (1,1145) dimensional vector\n    b2_fchl = do the above for building block 2 for that molecule\n    b3_fchl = do the above for building block 3 for that molecule\n    molecule_fchl = normalize(b1_fchl + b2_fchl + b3_fchl); a normalized (1,1145) dimensional vector\n    add molecule_fchl to feature_matrix\n\nnow, feature_matrix is of dimensionality N_train x 1145\nnow apply logistic + KRR to fit the above molecule_fchl with their corresponding binary binding labels\n\nfor molecule in test_set:\n    generate_molecule_fchl as done above\n    use the above logisitic + KRR model + some probability threshold to assing prediction binary binding label\n```","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}